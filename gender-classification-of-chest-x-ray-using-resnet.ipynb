{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af2112d0",
   "metadata": {
    "papermill": {
     "duration": 0.004657,
     "end_time": "2024-01-04T20:58:06.214296",
     "exception": false,
     "start_time": "2024-01-04T20:58:06.209639",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Classify gender of Chest X-ray images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63399140",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:58:06.224863Z",
     "iopub.status.busy": "2024-01-04T20:58:06.224185Z",
     "iopub.status.idle": "2024-01-04T20:58:16.416372Z",
     "shell.execute_reply": "2024-01-04T20:58:16.415262Z"
    },
    "papermill": {
     "duration": 10.200295,
     "end_time": "2024-01-04T20:58:16.419149",
     "exception": false,
     "start_time": "2024-01-04T20:58:06.218854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms import ToTensor, Compose, Resize, Grayscale, Normalize, Lambda\n",
    "import os\n",
    "import torchvision.transforms as T\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ea3f814",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:58:16.430619Z",
     "iopub.status.busy": "2024-01-04T20:58:16.429627Z",
     "iopub.status.idle": "2024-01-04T20:58:16.434853Z",
     "shell.execute_reply": "2024-01-04T20:58:16.433809Z"
    },
    "papermill": {
     "duration": 0.013115,
     "end_time": "2024-01-04T20:58:16.436937",
     "exception": false,
     "start_time": "2024-01-04T20:58:16.423822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8191af47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:58:16.446910Z",
     "iopub.status.busy": "2024-01-04T20:58:16.446563Z",
     "iopub.status.idle": "2024-01-04T20:58:16.451854Z",
     "shell.execute_reply": "2024-01-04T20:58:16.451004Z"
    },
    "papermill": {
     "duration": 0.012515,
     "end_time": "2024-01-04T20:58:16.453808",
     "exception": false,
     "start_time": "2024-01-04T20:58:16.441293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the training image directory and annotations csv\n",
    "train_img_dir = '/kaggle/input/minijsrtgender/dataset/Gender01'\n",
    "train_annotations_file = '/kaggle/input/minijsrtgender/dataset/Gender01/list_train.txt'\n",
    "\n",
    "# Define the testing image directory and annotations csv\n",
    "test_img_dir = '/kaggle/input/minijsrtgender/dataset/Gender01'\n",
    "test_annotations_file = '/kaggle/input/minijsrtgender/dataset/Gender01/list_test.txt'\n",
    "\n",
    "# Define the output classes here\n",
    "num_classes = 1\n",
    "\n",
    "# Defining the label mapping for each output\n",
    "label_mapping = {\n",
    "    'female': 0,\n",
    "    'male': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2bb912a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:58:16.463935Z",
     "iopub.status.busy": "2024-01-04T20:58:16.463291Z",
     "iopub.status.idle": "2024-01-04T20:58:16.471216Z",
     "shell.execute_reply": "2024-01-04T20:58:16.470305Z"
    },
    "papermill": {
     "duration": 0.015198,
     "end_time": "2024-01-04T20:58:16.473249",
     "exception": false,
     "start_time": "2024-01-04T20:58:16.458051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a custom class for dataset \n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_dir + self.img_labels.iloc[idx, 0]\n",
    "        image = read_image(img_path)\n",
    "        image = T.ToPILImage() (image)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3043051f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:58:16.483231Z",
     "iopub.status.busy": "2024-01-04T20:58:16.482928Z",
     "iopub.status.idle": "2024-01-04T20:58:16.489525Z",
     "shell.execute_reply": "2024-01-04T20:58:16.488615Z"
    },
    "papermill": {
     "duration": 0.013976,
     "end_time": "2024-01-04T20:58:16.491615",
     "exception": false,
     "start_time": "2024-01-04T20:58:16.477639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definining the resnet18 model\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import torch.nn as nn\n",
    "class Resnet18Classifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Resnet18Classifier, self).__init__()\n",
    "        self.resnet18 = resnet18(pretrained=True)\n",
    "        self.resnet18.fc = nn.Linear(self.resnet18.fc.in_features, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.sigmoid(self.resnet18(x))\n",
    "#         return self.resnet18(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f05c3f64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:58:16.501275Z",
     "iopub.status.busy": "2024-01-04T20:58:16.500976Z",
     "iopub.status.idle": "2024-01-04T20:58:16.541047Z",
     "shell.execute_reply": "2024-01-04T20:58:16.540174Z"
    },
    "papermill": {
     "duration": 0.04775,
     "end_time": "2024-01-04T20:58:16.543470",
     "exception": false,
     "start_time": "2024-01-04T20:58:16.495720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining the transform for loading the data\n",
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    Lambda(lambda x: x.repeat(3,1,1)),\n",
    "    Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Defining the training dataset and data loader\n",
    "train_dataset = CustomDataset(\n",
    "    annotations_file=train_annotations_file,\n",
    "    img_dir=train_img_dir,\n",
    "    transform=transform,\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Defining the testing dataset and data loader\n",
    "test_dataset = CustomDataset(\n",
    "    annotations_file=test_annotations_file,\n",
    "    img_dir=test_img_dir,\n",
    "    transform=transform\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e00edb33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:58:16.553513Z",
     "iopub.status.busy": "2024-01-04T20:58:16.553162Z",
     "iopub.status.idle": "2024-01-04T20:58:17.520224Z",
     "shell.execute_reply": "2024-01-04T20:58:17.519158Z"
    },
    "papermill": {
     "duration": 0.975326,
     "end_time": "2024-01-04T20:58:17.523215",
     "exception": false,
     "start_time": "2024-01-04T20:58:16.547889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 204MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Initializing the resnet18 classifier with number of output models\n",
    "resnet_18_classifier = Resnet18Classifier(num_classes).to(device)\n",
    "\n",
    "# Defining the loss_function and the optimizer\n",
    "loss_func = nn.BCELoss()\n",
    "optimizer = optim.Adam(resnet_18_classifier.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81ddbd99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:58:17.535315Z",
     "iopub.status.busy": "2024-01-04T20:58:17.534442Z",
     "iopub.status.idle": "2024-01-04T20:58:17.543631Z",
     "shell.execute_reply": "2024-01-04T20:58:17.542528Z"
    },
    "papermill": {
     "duration": 0.01823,
     "end_time": "2024-01-04T20:58:17.546498",
     "exception": false,
     "start_time": "2024-01-04T20:58:17.528268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resnet18Classifier(\n",
       "  (resnet18): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_18_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abfeaaed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:58:17.559363Z",
     "iopub.status.busy": "2024-01-04T20:58:17.558446Z",
     "iopub.status.idle": "2024-01-04T20:59:27.408392Z",
     "shell.execute_reply": "2024-01-04T20:59:27.407302Z"
    },
    "papermill": {
     "duration": 69.858623,
     "end_time": "2024-01-04T20:59:27.410603",
     "exception": false,
     "start_time": "2024-01-04T20:58:17.551980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.5170\n",
      "Epoch [2/100], Loss: 0.2898\n",
      "Epoch [3/100], Loss: 0.1058\n",
      "Epoch [4/100], Loss: 0.0242\n",
      "Epoch [5/100], Loss: 0.0050\n",
      "Epoch [6/100], Loss: 0.0046\n",
      "Epoch [7/100], Loss: 0.0004\n",
      "Epoch [8/100], Loss: 0.0010\n",
      "Epoch [9/100], Loss: 0.0011\n",
      "Epoch [10/100], Loss: 0.0011\n",
      "Epoch [11/100], Loss: 0.0005\n",
      "Epoch [12/100], Loss: 0.0006\n",
      "Epoch [13/100], Loss: 0.0004\n",
      "Epoch [14/100], Loss: 0.0006\n",
      "Epoch [15/100], Loss: 0.0291\n",
      "Epoch [16/100], Loss: 0.0046\n",
      "Epoch [17/100], Loss: 0.0005\n",
      "Epoch [18/100], Loss: 0.0094\n",
      "Epoch [19/100], Loss: 0.0354\n",
      "Epoch [20/100], Loss: 0.3425\n",
      "Epoch [21/100], Loss: 0.4231\n",
      "Epoch [22/100], Loss: 0.0161\n",
      "Epoch [23/100], Loss: 0.0235\n",
      "Epoch [24/100], Loss: 0.6612\n",
      "Epoch [25/100], Loss: 0.1824\n",
      "Epoch [26/100], Loss: 0.0082\n",
      "Epoch [27/100], Loss: 0.4943\n",
      "Epoch [28/100], Loss: 0.2190\n",
      "Epoch [29/100], Loss: 0.0193\n",
      "Epoch [30/100], Loss: 0.1273\n",
      "Epoch [31/100], Loss: 0.2497\n",
      "Epoch [32/100], Loss: 0.4035\n",
      "Epoch [33/100], Loss: 0.0220\n",
      "Epoch [34/100], Loss: 0.2471\n",
      "Epoch [35/100], Loss: 0.5357\n",
      "Epoch [36/100], Loss: 0.0677\n",
      "Epoch [37/100], Loss: 0.0014\n",
      "Epoch [38/100], Loss: 0.0069\n",
      "Epoch [39/100], Loss: 0.0032\n",
      "Epoch [40/100], Loss: 0.0007\n",
      "Epoch [41/100], Loss: 0.0005\n",
      "Epoch [42/100], Loss: 0.0047\n",
      "Epoch [43/100], Loss: 0.0359\n",
      "Epoch [44/100], Loss: 0.0017\n",
      "Epoch [45/100], Loss: 0.0001\n",
      "Epoch [46/100], Loss: 0.0010\n",
      "Epoch [47/100], Loss: 0.2879\n",
      "Epoch [48/100], Loss: 0.0223\n",
      "Epoch [49/100], Loss: 0.0015\n",
      "Epoch [50/100], Loss: 0.0320\n",
      "Epoch [51/100], Loss: 0.0005\n",
      "Epoch [52/100], Loss: 0.0028\n",
      "Epoch [53/100], Loss: 0.0007\n",
      "Epoch [54/100], Loss: 0.0003\n",
      "Epoch [55/100], Loss: 0.0001\n",
      "Epoch [56/100], Loss: 0.0013\n",
      "Epoch [57/100], Loss: 0.0001\n",
      "Epoch [58/100], Loss: 0.0009\n",
      "Epoch [59/100], Loss: 0.0009\n",
      "Epoch [60/100], Loss: 0.0447\n",
      "Epoch [61/100], Loss: 0.0002\n",
      "Epoch [62/100], Loss: 0.0002\n",
      "Epoch [63/100], Loss: 0.0003\n",
      "Epoch [64/100], Loss: 0.0083\n",
      "Epoch [65/100], Loss: 0.0000\n",
      "Epoch [66/100], Loss: 0.0001\n",
      "Epoch [67/100], Loss: 0.0002\n",
      "Epoch [68/100], Loss: 0.0001\n",
      "Epoch [69/100], Loss: 0.0002\n",
      "Epoch [70/100], Loss: 0.0001\n",
      "Epoch [71/100], Loss: 0.0000\n",
      "Epoch [72/100], Loss: 0.0004\n",
      "Epoch [73/100], Loss: 0.0001\n",
      "Epoch [74/100], Loss: 0.0000\n",
      "Epoch [75/100], Loss: 0.0001\n",
      "Epoch [76/100], Loss: 0.0000\n",
      "Epoch [77/100], Loss: 0.0004\n",
      "Epoch [78/100], Loss: 0.0012\n",
      "Epoch [79/100], Loss: 0.0001\n",
      "Epoch [80/100], Loss: 0.4077\n",
      "Epoch [81/100], Loss: 0.0343\n",
      "Epoch [82/100], Loss: 0.0166\n",
      "Epoch [83/100], Loss: 0.2958\n",
      "Epoch [84/100], Loss: 0.0208\n",
      "Epoch [85/100], Loss: 0.3038\n",
      "Epoch [86/100], Loss: 0.4300\n",
      "Epoch [87/100], Loss: 0.0108\n",
      "Epoch [88/100], Loss: 0.2343\n",
      "Epoch [89/100], Loss: 0.0149\n",
      "Epoch [90/100], Loss: 0.0013\n",
      "Epoch [91/100], Loss: 0.0054\n",
      "Epoch [92/100], Loss: 0.0036\n",
      "Epoch [93/100], Loss: 0.0015\n",
      "Epoch [94/100], Loss: 0.0002\n",
      "Epoch [95/100], Loss: 0.0001\n",
      "Epoch [96/100], Loss: 0.0281\n",
      "Epoch [97/100], Loss: 0.0003\n",
      "Epoch [98/100], Loss: 0.0010\n",
      "Epoch [99/100], Loss: 0.0029\n",
      "Epoch [100/100], Loss: 0.0003\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        numeric_labels = [label_mapping[label] for label in labels]\n",
    "        numeric_labels_tensor = torch.tensor(numeric_labels)\n",
    "        images, labels = images.to(device), numeric_labels_tensor.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet_18_classifier(images)\n",
    "        outputs = outputs.float().squeeze()\n",
    "        labels = labels.float()\n",
    "#         print(f\"Outputs are {outputs}\")                \n",
    "#         print(f\"Labels are {labels}\")\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"Training finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72f38248",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T20:59:27.439908Z",
     "iopub.status.busy": "2024-01-04T20:59:27.439170Z",
     "iopub.status.idle": "2024-01-04T20:59:28.503758Z",
     "shell.execute_reply": "2024-01-04T20:59:28.502597Z"
    },
    "papermill": {
     "duration": 1.081303,
     "end_time": "2024-01-04T20:59:28.505845",
     "exception": false,
     "start_time": "2024-01-04T20:59:27.424542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auc for batch: 0.98\n",
      "Auc for batch: 0.73\n",
      "Auc for batch: 0.89\n",
      "Auc for batch: 1.00\n",
      "Auc for batch: 0.83\n",
      "Auc for batch: 1.00\n",
      "Test auc for gender classification: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "correct = 0\n",
    "total_auc = 0\n",
    "total_counts = 0\n",
    "# Don't calculate gradients during evaluation\n",
    "with torch.no_grad():\n",
    "    resnet_18_classifier.eval()\n",
    "    for images, labels in test_loader:\n",
    "        numeric_labels = [label_mapping[label] for label in labels]\n",
    "        numeric_labels_tensor = torch.tensor(numeric_labels)\n",
    "        images, labels = images.to(device), numeric_labels_tensor.to(device)\n",
    "        outputs = resnet_18_classifier(images)\n",
    "        labels = labels.cpu()\n",
    "        outputs = outputs.cpu()\n",
    "        auc = roc_auc_score(labels, outputs)\n",
    "        total_auc += auc\n",
    "        total_counts += 1\n",
    "        print(f'Auc for batch: {auc:.2f}')\n",
    "\n",
    "final_auc = total_auc / total_counts\n",
    "print(f\"Test auc for gender classification: {final_auc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a586be01",
   "metadata": {
    "papermill": {
     "duration": 0.012791,
     "end_time": "2024-01-04T20:59:28.531955",
     "exception": false,
     "start_time": "2024-01-04T20:59:28.519164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3926975,
     "sourceId": 6829646,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30559,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 89.599738,
   "end_time": "2024-01-04T20:59:30.876583",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-04T20:58:01.276845",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
